# Projeto Final de Engenharia de Dados IBM

Este é o repositório do projeto final desenvolvido para o curso "Certificado Profissional IBM Data Engineering", que culmina na certificação do aluno.

O escopo do projeto é o "IBM Data Engineering Capstone Project", onde o aluno assume o papel de um Junior Data Engineer e trabalha com dados de vendas de e-commerce.

O projeto é dividido em seis módulos, cada um com suas próprias tarefas e ferramentas de software:

## Módulo 1:
- Criar um banco de dados no MySQL para OLTP (ou seja, para dados de vendas).
- Criar uma tabela de sales_data e carregar os dados usando a interface gráfica do PhpMyAdmin.
- Verificar o número total de registros usando a CLI do MySQL.
- Exportar os dados para sales_data.sql usando o comando mysqldump.
- Ferramentas / software: MySQL e PhpMyAdmin.

## Módulo 2:
- Importar o banco de dados do catálogo que está no formato JSON.
- Realizar operações agregadas nos dados da coleção "eletrônicos".
- Exportar os dados da coleção "eletrônicos" em formato CSV usando o comando mongoexport.
- Ferramentas / software: MongoDB Server e MongoDB Command Line Backup Tools.

## Módulo 3:
- Criar tabelas de fatos e dimensões usando ERD e estabelecer relações entre elas.
- Gerar a consulta SQL do esquema usando o gerador de consultas ERD.
- Executar a consulta SQL do esquema no IBM DB2 Cloud para criar as tabelas e carregar os dados nelas usando pgAdmin.
- Analisar os dados das tabelas.
- Ferramentas / software: ERD Design Tool do pgAdmin e PostgreSQL Database Server.

## Módulo 4:
- Importar os dados de vendas no IBM Cognos, que está na nuvem da IBM.
- Usar a interface do dashboard do IBM Cognos para criar gráficos de pizza e barras para os dados de histórico de vendas.
- Ferramentas / software: IBM Cognos Analytics e instância de nuvem do banco de dados IBM DB2.

## Módulo 5:
- Fazer conexão com o MySQL usando Python e criar um banco de dados e carregar dados de exemplo.
- Em seguida, criar uma conexão com IBM_DB2 na nuvem e carregar os dados nele.
- Implementar o processo acima usando o Apache Airflow.

## Módulo 6:
- Importar o PySpark, FindSpark e Pandas e criar o contexto e a sessão do Spark.
- Importar os dados de exemplo e lê-los usando o Pandas.
- Usar o Spark SQL para analisar os dados de pesquisa de itens.
- Importar o modelo de regressão linear do PySpark e carregar os dados de previsão de vendas para prever as vendas para o ano de 2023.

Esse é um projeto desafiador e completo que ajuda a desenvolver habilidades de engenharia de dados com ferramentas e tecnologias da IBM. Esperamos que seja útil e divertido!
